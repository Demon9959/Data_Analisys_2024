{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведіть експерименти з моделями бібліотеки Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ukr-models/uk-ner\")\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"ukr-models/uk-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity': 'B-PER',\n",
       "  'score': 0.96217775,\n",
       "  'index': 3,\n",
       "  'word': '▁Тарас',\n",
       "  'start': 6,\n",
       "  'end': 12},\n",
       " {'entity': 'B-PER',\n",
       "  'score': 0.95024234,\n",
       "  'index': 4,\n",
       "  'word': 'а',\n",
       "  'start': 12,\n",
       "  'end': 13},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.8984033,\n",
       "  'index': 5,\n",
       "  'word': '▁Шевченка',\n",
       "  'start': 13,\n",
       "  'end': 22},\n",
       " {'entity': 'B-PER',\n",
       "  'score': 0.9997545,\n",
       "  'index': 16,\n",
       "  'word': '▁Тарас',\n",
       "  'start': 69,\n",
       "  'end': 75},\n",
       " {'entity': 'B-PER',\n",
       "  'score': 0.9999771,\n",
       "  'index': 17,\n",
       "  'word': 'а',\n",
       "  'start': 75,\n",
       "  'end': 76},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99953413,\n",
       "  'index': 18,\n",
       "  'word': '▁Шевченка',\n",
       "  'start': 76,\n",
       "  'end': 85},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9999757,\n",
       "  'index': 21,\n",
       "  'word': '▁Кан',\n",
       "  'start': 93,\n",
       "  'end': 97},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.99998057,\n",
       "  'index': 22,\n",
       "  'word': 'ів',\n",
       "  'start': 97,\n",
       "  'end': 99},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9999881,\n",
       "  'index': 24,\n",
       "  'word': 'Чер',\n",
       "  'start': 101,\n",
       "  'end': 104},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9999877,\n",
       "  'index': 25,\n",
       "  'word': 'ка',\n",
       "  'start': 104,\n",
       "  'end': 106},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9999877,\n",
       "  'index': 26,\n",
       "  'word': 'ська',\n",
       "  'start': 106,\n",
       "  'end': 110},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.99997425,\n",
       "  'index': 27,\n",
       "  'word': '▁область',\n",
       "  'start': 110,\n",
       "  'end': 118},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9999863,\n",
       "  'index': 30,\n",
       "  'word': '▁Черн',\n",
       "  'start': 122,\n",
       "  'end': 127},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.99998605,\n",
       "  'index': 31,\n",
       "  'word': 'е',\n",
       "  'start': 127,\n",
       "  'end': 128},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.9999865,\n",
       "  'index': 32,\n",
       "  'word': 'чі',\n",
       "  'start': 128,\n",
       "  'end': 130},\n",
       " {'entity': 'B-LOC',\n",
       "  'score': 0.99998784,\n",
       "  'index': 33,\n",
       "  'word': 'й',\n",
       "  'start': 130,\n",
       "  'end': 131},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9999733,\n",
       "  'index': 34,\n",
       "  'word': '▁гор',\n",
       "  'start': 131,\n",
       "  'end': 135},\n",
       " {'entity': 'I-LOC',\n",
       "  'score': 0.9999783,\n",
       "  'index': 35,\n",
       "  'word': 'і',\n",
       "  'start': 135,\n",
       "  'end': 136},\n",
       " {'entity': 'B-PER',\n",
       "  'score': 0.9999901,\n",
       "  'index': 56,\n",
       "  'word': '▁Мат',\n",
       "  'start': 205,\n",
       "  'end': 209},\n",
       " {'entity': 'B-PER',\n",
       "  'score': 0.9999887,\n",
       "  'index': 57,\n",
       "  'word': 'ві',\n",
       "  'start': 209,\n",
       "  'end': 211},\n",
       " {'entity': 'B-PER',\n",
       "  'score': 0.9999876,\n",
       "  'index': 58,\n",
       "  'word': 'я',\n",
       "  'start': 211,\n",
       "  'end': 212},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9999902,\n",
       "  'index': 59,\n",
       "  'word': '▁Ма',\n",
       "  'start': 212,\n",
       "  'end': 215},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.9999926,\n",
       "  'index': 60,\n",
       "  'word': 'ніз',\n",
       "  'start': 215,\n",
       "  'end': 218},\n",
       " {'entity': 'I-PER',\n",
       "  'score': 0.99999154,\n",
       "  'index': 61,\n",
       "  'word': 'ера',\n",
       "  'start': 218,\n",
       "  'end': 221}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "nlp(\"Могила Тараса Шевченка — місце поховання видатного українського поета Тараса Шевченка в місті Канів (Черкаська область) на Чернечій горі, над яким із 1939 року височіє бронзовий пам'ятник роботи скульптора Матвія Манізера.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: lord of the rings\n",
      "Generated Text: lord of the rings is a powerful figurehead who has managed to bring order to the situation. A series of events leading up to and before his demise eventually lead to the destruction of the city of Kree and the destruction of the planet that still resides here on this planet.\n",
      "\n",
      "The next major event of Season 7 is that of the return of the Shadow and the beginning of its journey to this world. In this third season, after the destruction of Rime, the Shadow returns to the K\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = 'lord of the rings'\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "generated = generator(prompt, max_length=100, num_return_sequences=1)\n",
    "print(f\"Prompt: {prompt}\\nGenerated Text: {generated[0]['generated_text']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
